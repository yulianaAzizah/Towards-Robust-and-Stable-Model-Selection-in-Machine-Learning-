{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qq4YdXzq2DF5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy as sp\n",
        "from scipy import stats\n",
        "import pandas as pd\n",
        "from pandas.api.types import CategoricalDtype\n",
        "import time\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_validate, KFold\n",
        "from sklearn.preprocessing import OrdinalEncoder, MinMaxScaler, StandardScaler\n",
        "from sklearn.metrics import r2_score, mean_squared_error, accuracy_score, mean_absolute_error, make_scorer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('rawdata.csv', delimiter=';')"
      ],
      "metadata": {
        "id": "lCeIZwy62N2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SS = StandardScaler()\n",
        "df_trans = SS.transform(df)"
      ],
      "metadata": {
        "id": "iPmUldaW2Tps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = PCA(n_components=1)\n",
        "df['PCA'] = model.fit_transform(df.iloc[:,2:4].values)"
      ],
      "metadata": {
        "id": "bSlvUcL72nx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop(labels='Lifetime', axis=1)\n",
        "y = df['Lifetime']"
      ],
      "metadata": {
        "id": "tI9_RoE53BIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"LR\": Ridge(),\n",
        "    \"SVM\": SVR(kernel='rbf'),\n",
        "    \"DT\": DecisionTreeRegressor(random_state=123),\n",
        "    \"RF\": RandomForestRegressor(n_estimators=10, random_state=123),\n",
        "    \"XGB\": XGBRegressor(objective='reg:squarederror', n_estimators=10, seed=123)\n",
        "}\n",
        "\n",
        "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "scoring = {\n",
        "    'r2': 'r2',\n",
        "    'neg_mse': 'neg_mean_squared_error',\n",
        "    'neg_rmse': make_scorer(lambda y_true, y_pred: -np.sqrt(mean_squared_error(y_true, y_pred))),\n",
        "    'neg_mae': 'neg_mean_absolute_error'\n",
        "}\n",
        "\n",
        "results_all = []\n",
        "\n",
        "for name, model in models.items():\n",
        "    scores = cross_validate(model, X, y, cv=cv, scoring=scoring)\n",
        "\n",
        "    for s in scores['test_r2']:\n",
        "        results_all.append({'Model': name, 'Metric': 'R2', 'Score': s})\n",
        "    for s in scores['test_neg_rmse']:\n",
        "        results_all.append({'Model': name, 'Metric': 'RMSE', 'Score': -s})\n",
        "    for s in scores['test_neg_mse']:\n",
        "        results_all.append({'Model': name, 'Metric': 'MSE', 'Score': -s})\n",
        "    for s in scores['test_neg_mae']:\n",
        "        results_all.append({'Model': name, 'Metric': 'MAE', 'Score': -s})\n",
        "\n",
        "df_results = pd.DataFrame(results_all)\n",
        "\n",
        "\n",
        "fig, axes = plt.subplots(4, 1, figsize=(8, 12), sharex=False)\n",
        "metrics = ['R2', 'RMSE', 'MSE', 'MAE']\n",
        "\n",
        "for i, metric in enumerate(metrics):\n",
        "    sns.boxplot(\n",
        "        data=df_results[df_results['Metric'] == metric],\n",
        "        x='Score',\n",
        "        y='Model',\n",
        "        ax=axes[i],\n",
        "        palette='Set2'\n",
        "    )\n",
        "    axes[i].set_title(metric)\n",
        "    axes[i].grid(True, axis='x')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vXBmd45N9I1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Single Evaluation"
      ],
      "metadata": {
        "id": "TThAbao5-qn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, shuffle=True, random_state=42\n",
        ")\n",
        "\n",
        "def evaluate_model(model, name):\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mae = np.mean(np.abs(y_test - y_pred))\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f\"{name:<20} =>  R²: {r2:.3f}  RMSE: {rmse:.3f}  MSE: {mse:.3f}  MAE: {mae:.3f}  | Time: {elapsed_time:.2f}s\")\n",
        "\n",
        "\n",
        "models = {\n",
        "    \"Linear Regression\": LinearRegression(),\n",
        "    \"SVM\": SVR(),\n",
        "    \"Decision Tree\": DecisionTreeRegressor(random_state=123),\n",
        "    \"Random Forest\": RandomForestRegressor(random_state=123),\n",
        "    \"XGBoost\": XGBRegressor(random_state=123)\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    evaluate_model(model, name)"
      ],
      "metadata": {
        "id": "E8MlwGre3B9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Optimization"
      ],
      "metadata": {
        "id": "JpMLQTgP-7UN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "xgb_regressor = XGBRegressor(objective='reg:squarederror',\n",
        "                             n_estimators=300,\n",
        "                             random_state=123)\n",
        "\n",
        "param = {\n",
        "    'learning_rate': [i/10 for i in range(1, 11)],\n",
        "    'max_depth': list(range(1, 21)),\n",
        "    'reg_alpha': list(range(1, 11)),\n",
        "    'reg_lambda': list(range(1, 11))\n",
        "}\n",
        "\n",
        "\n",
        "grid_search = GridSearchCV(estimator=xgb_regressor,\n",
        "                           param_grid=param,\n",
        "                           scoring='neg_mean_squared_error',\n",
        "                           cv=5,\n",
        "                           n_jobs=-1)\n",
        "random_search = RandomizedSearchCV(estimator=xgb_regressor,\n",
        "                                   param_distributions=param,\n",
        "                                   scoring='neg_mean_squared_error',\n",
        "                                   n_iter=50,\n",
        "                                   cv=5,\n",
        "                                   n_jobs=-1,\n",
        "                                   random_state=123)\n",
        "bayes_search = BayesSearchCV(estimator=xgb_regressor,\n",
        "                             search_spaces=param,\n",
        "                             scoring='neg_mean_squared_error',\n",
        "                             n_iter=50,\n",
        "                             cv=5,\n",
        "                             n_jobs=-1,\n",
        "                             random_state=123)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "random_search.fit(X_train, y_train)\n",
        "bayes_search.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "XM-oKKk93ixB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_train, y_train, X_test, y_test, name):\n",
        "    start = time.time()\n",
        "    best_model = model.best_estimator_\n",
        "    best_model.set_params(n_estimators=1000, early_stopping_rounds=10)\n",
        "\n",
        "    best_model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=False)\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    mae = np.mean(np.abs(y_test - y_pred))\n",
        "    elapsed = time.time() - start\n",
        "\n",
        "    return {\n",
        "        \"Method\": name,\n",
        "        \"R²\": round(r2, 3),\n",
        "        \"RMSE\": round(rmse, 3),\n",
        "        \"MSE\": round(mse, 3),\n",
        "        \"MAE\": round(mae, 3),\n",
        "        \"Exec_Time (s)\": round(elapsed, 2)\n",
        "    }\n",
        "\n",
        "\n",
        "print(\"Running Grid Search...\")\n",
        "grid_search.fit(X_train, y_train)\n",
        "print(\"Running Random Search...\")\n",
        "random_search.fit(X_train, y_train)\n",
        "print(\"Running Bayesian Optimization...\")\n",
        "bayes_search.fit(X_train, y_train)\n",
        "\n",
        "results = []\n",
        "results.append(evaluate_model(grid_search, X_train, y_train, X_test, y_test, \"Grid Search\"))\n",
        "results.append(evaluate_model(random_search, X_train, y_train, X_test, y_test, \"Random Search\"))\n",
        "results.append(evaluate_model(bayes_search, X_train, y_train, X_test, y_test, \"Bayesian Optimization\"))\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"Model Evaluation Summary\")\n",
        "print(results_df.to_string(index=False))\n"
      ],
      "metadata": {
        "id": "kH8xnMqM_i9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_results = {\n",
        "    \"Grid\": [r2],\n",
        "    \"Random\": [results_df.loc[results_df[\"Method\"] == \"Random Search\", \"R²\"].values[0]],\n",
        "    \"Bayes\": [results_df.loc[results_df[\"Method\"] == \"Bayesian Optimization\", \"R²\"].values[0]]\n",
        "}\n",
        "\n",
        "labels = [\"XGB\"]\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(12, 6), sharey=True)\n",
        "\n",
        "for i, method in enumerate(plot_results.keys()):\n",
        "    axes[i].boxplot(plot_results[method])\n",
        "    axes[i].set_title(method)\n",
        "    axes[i].set_xticklabels(labels, rotation=45)\n",
        "    axes[i].set_ylabel(\"R² Score\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vDhxpou9CKFF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}